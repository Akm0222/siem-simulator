# This is the INPUT section. It tells Logstash where to get data from.
input {
  file {
    path => "/var/log/applogs/app.log" # Reads the log file from inside the container
    start_position => "beginning"
    sincedb_path => "/dev/null" # Forgets read position on restart (good for demos)
  }
}

# This is the FILTER section. It processes and enriches the log data.
filter {
  # Rule for SSH logs
  if "sshd" in [message] {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:timestamp} %{HOSTNAME:hostname} sshd\[%{NUMBER:pid}\]: %{DATA:ssh_message} for %{USERNAME:user} from %{IP:source_ip}" }
    }
    mutate { add_field => { "event_type" => "ssh_auth" } }
    
    # Threat detection for failed logins
    if "Failed password" in [message] {
      mutate {
        add_tag => ["threat_detected", "failed_login"]
        add_field => { "threat_level" => "medium" }
      }
    }

  # Rule for Apache web server logs
  } else if [message] =~ /HTTP/ {
    grok {
      match => { "message" => "%{IPORHOST:clientip} %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] \"%{WORD:verb} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\" %{NUMBER:response} %{NUMBER:bytes}" }
    }
    mutate { add_field => { "event_type" => "apache_access" } }
  
  # Rule for Firewall logs
  } else if "UFW BLOCK" in [message] {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:timestamp} %{HOSTNAME:hostname} kernel: \[UFW BLOCK\] IN=%{WORD:iface} OUT= MAC=%{GREEDYDATA:mac} SRC=%{IP:source_ip} DST=%{IP:dest_ip} PROTO=%{WORD:protocol}" }
    }
    # Threat detection for any firewall block
    mutate {
      add_tag => ["threat_detected", "firewall_drop"]
      add_field => { "event_type" => "firewall" }
      add_field => { "threat_level" => "high" }
    }

  # Rule for Application Error logs
  } else if "ERROR" in [message] {
    grok {
      match => { "message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] \[%{LOGLEVEL:log_level}\] \[%{DATA:service}\] %{GREEDYDATA:error_message}"}
    }
    mutate { add_field => { "event_type" => "application_error" } }
  }

  # Add location data based on the source IP address
  geoip {
    source => "source_ip"
  }
}

# This is the OUTPUT section. It tells Logstash where to send the processed data.
output {
  # Send data to Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "siem-logs-%{+YYYY.MM.dd}"
  }
  # Also print data to the console for easy debugging
  stdout { codec => rubydebug }
}